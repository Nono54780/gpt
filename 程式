from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
import pandas as pd
import numpy as np

# 手動輸入歷史中獎號碼，
history_nums = [  [32,25,9,39,4],[8,10,25,12,6 ],[14,12,34,30,25 ],[29,8,31,36,18 ],[17,26,29,36,39],[30,38,10,35,39],[6,8,30,23,3],[6,34,30,31,13],[22,2,18,29,8],[34,31,23,26,35],[29,26,3,37,14],[26,9,31,4,29],[29,12,23,8,4],[29,7,12,4,11],[39,6,4,26,28],[12,34,39,18,6],[1,12,34,3,28],[15,19,25,5,6],[12,8,28,35,14],[13,22,14,4,12],[6,8,16,19,31],[20,19,5,1,15],[36,12,33,6,10],[24,2,19,16,27],[32,18,38,29,9],[25,6,17,18,8],[6,38,3,23,2],[19,38,16,23,36],[30,11,12,38,27],[21,7,19,31,1],[22,18,24,13,15],[16,15,31,28,3],[13,1,25, 26,27],[15,17, 28,37,13],[35,32,22,39,        38],[4,26,17,34,25],[7,30,27,39,31],[34,31,5,16,6],[16,37,12,28,9],[37,32,4,24,23],[35,5,25,39,17],[31,9,25,27,22],[18,12,32,20,8],[14,24,30,32,38],[37,29,2,25,17],[16,37,2,17,11],[13,11,7,17,27],[12,11,16,8,30],[4,6,27,39,38],[21,5,38,31,33],[8,27,6,33,23],[37,26,30,32,36],[4,37,24,9,1]
]

# 方法1: 機器學習，使用決策樹模型
dtc = DecisionTreeClassifier(random_state=0)
train_X = np.array([item[0] for item in history_nums[:-1]])
train_y = np.array([item[0] for item in history_nums[-1]])
dtc.fit(train_X.reshape(-1, 1), train_y)
ml_predict = dtc.predict(np.array([item[0] for item in history_nums[:-1]]).reshape(-1, 1))
print("方法1 機器學習預測：", ml_predict)

# 方法2: 統計學，預測下一個號碼出現的機率最高的5個號碼
data = pd.DataFrame(history_nums,
                    columns=["num1", "num2", "num3", "num4", "num5"])
most_frequent = data.iloc[:-1, 0].value_counts().head(5)
stat_predict = most_frequent.index.tolist()
print("方法2 統計學預測：", stat_predict)

# 方法3: 貝葉斯理論，使用貝葉斯分類器
gnb = GaussianNB()
train_X = np.array([item[0] for item in history_nums[:2]]).reshape(-1, 1)
train_y = np.array(history_nums[2][0])
gnb.fit(train_X, train_y)
bayes_predict = gnb.predict(np.array([item[0] for item in history_nums[:2]]).reshape(-1, 1))
print("方法3 貝葉斯理論預測：", bayes_predict)
